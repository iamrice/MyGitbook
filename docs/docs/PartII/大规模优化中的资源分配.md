<h1>大规模优化中的资源分配 🕵️‍♂️</h1>

加油加油，争取这学期做完这个工作，然后再来写总结，我要carry!!!

###前期学习（5月-9月)

#### 大规模优化
两篇大规模优化文章
> LLSO: A Level-Based Learning Swarm Optimizer  
> DCCA: Distributed Cooperative Co-Evolution With Adaptive Computing Resource Allocation 

大规模问题分组策略  
> DG: differential grouping   
> GDG: global differential grouping  

大规模问题测试集  
> cec2010-Benchmark-Functions  
> cec2013-Benchmark-Functions  

#### Hadoop分布式计算框架
> map-reduce  

#### 实验室集群
> 在集群上配置hadoop运行环境，告别虚拟机

###实验一（9-10月）

###实验二（10月-11月）

###实验三（11月）

<p style="display: none"> 
1.  Wilcoxon rank sum test：显著性检验
像文章一样绘一张表，并额外加一列记录best-worst-p-value
2. 这次实验把数据做的专业一点，均值、中位值、std、pvalue，使用python，都可以算的。
3. 对比放大参数部分与剩余部分的资源分布  

1. 关于分配区间的讨论点：对未来一个区间的预测准确性

2. 不同分组在演化过程中的优化速度，画出曲线；分析相对大小（肉眼或某种模型）  

> 代码调整方法：写文件时同时写上每一组的bestvalue，并且改为静态分配(interval=250)，每个函数运行5次就行

3. 分配间隔长的，分配的量是不是应该变多：可试验

> 代码调整方法：每次调整量为间隔，但依然保证资源在1-6之间

3.5 一定是看250次迭代的结果吗，150次？通过参数放大来模拟不平衡性，在放大优化区间的同时，也放大了优化速度，时间大致没有改变，所以在计算资源不充足的情况下才比较能体现出不平衡性。现在放大100倍和1000倍没有太体现出差异性。

4. 寒假能不能留实验室

5. 推免名额

数据分析：
1. 不同分配间隔的结果确实有差异，不过没有找到合理的解释
2. 对完全可分割，f2没有显著差异，f1中，在迭代中间阶段，分化明显，分配区间大的下降更快，在后期阶段，趋于统一
3. 对部分可分割，f8的五组实验中，都是interval=1表现最佳，f9也是，在差异明显的组别中，interval=1更优
4. 对链式不可分，f14没有显著差异，f13很早就快就趋于平缓了，感觉随机因素影响挺大的

发现的问题，globalbest不必每次都同步，每周期同步即可，所以画出来的曲线跨度不一样

mpi+openmp
mpi划分group，openmp划分particle，不过这个cpu总数要怎么给?按mpi？
消息传递：每周期传数据到mpi的主进程，然后主进程再返回bestpar

hadoop用的难受~~~想换mpi了，顺便当成高性能实验吧，如果老师不强制做多体问题的话。
实验四跑了一半，不想跑了555，担心出错。
</p>